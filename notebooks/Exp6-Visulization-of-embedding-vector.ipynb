{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52abfd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rc/.local/lib/python3.10/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import pinecone\n",
    "import numpy as np\n",
    "from nomic import atlas\n",
    "import nomic\n",
    "from tqdm import tqdm \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "import json \n",
    "\n",
    "load_dotenv()\n",
    "openai_key = os.getenv('OPENAI_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = openai_key\n",
    "\n",
    "pinecone_api_key = os.getenv('PINECONE_KEY')\n",
    "pinecone_env_name = os.getenv('PINECONE_ENV')\n",
    "pinecone_index_name = os.getenv('PINECONE_INDEX')\n",
    "nomic_api_key = os.getenv('NOMIC_KEY')\n",
    "\n",
    "pinecone_config = {\n",
    "    \"api_key\":pinecone_api_key,\n",
    "    \"env_name\":pinecone_env_name,\n",
    "    \"index_name\":pinecone_index_name\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091b3c79",
   "metadata": {},
   "source": [
    "# Vectors Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69979c6f",
   "metadata": {},
   "source": [
    "<font size=4 color=blue> This time I get the embedding vectors locally rather than fetching the vectors from Pinecone, because cloud vector database has limitations of fetching the vectors (bandwidth and keys encryption). For visulization and experiment purpose, it is suggested that embeding and saving the vectors before upserting to vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d152cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_directory = \"../docs\"\n",
    "# my_loader = DirectoryLoader(pdf_directory, glob='**/*.pdf')\n",
    "# documents = my_loader.load()\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100)\n",
    "# docs = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b4fc694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Uncomment for first time uses\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "# chunk_dicts = {\n",
    "#     \"text\":[],\n",
    "#     \"vectors\":[],\n",
    "#     \"categories\":[]\n",
    "# }\n",
    "\n",
    "# for chunk in tqdm(docs):\n",
    "#     chunk_text = chunk.page_content\n",
    "#     chunk_embedded_vector = embeddings.embed_documents([chunk_text])    \n",
    "\n",
    "#     chunk_dicts[\"vectors\"].append(chunk_embedded_vector)\n",
    "#     chunk_dicts[\"categories\"].append(\"pdf_chunk_embeddings\")\n",
    "#     chunk_dicts[\"text\"].append([chunk_text])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd3a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# with open('pdf_embedding.json', 'w') as f:\n",
    "#     # Use json.dump to write the data to the file.\n",
    "#     json.dump(chunk_dicts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8eb8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pdf_embedding.json', 'r') as f:\n",
    "    # Use json.load to load the data from the file.\n",
    "    pdf_embedding = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f7aae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-03 16:41:53.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.project\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m749\u001b[0m - \u001b[1mCreating project `oafish-oxford` in organization `rancheng0918`\u001b[0m\n",
      "\u001b[32m2023-07-03 16:41:55.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUploading embeddings to Atlas.\u001b[0m\n",
      "\u001b[32m2023-07-03 16:41:55.384\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnomic.project\u001b[0m:\u001b[36m_validate_and_correct_arrow_upload\u001b[0m:\u001b[36m254\u001b[0m - \u001b[33m\u001b[1mid_field is not a string. Converting to string from int32\u001b[0m\n",
      "2it [00:03,  1.60s/it]                                                          \n",
      "\u001b[32m2023-07-03 16:41:58.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.project\u001b[0m:\u001b[36m_add_data\u001b[0m:\u001b[36m1371\u001b[0m - \u001b[1mUpload succeeded.\u001b[0m\n",
      "\u001b[32m2023-07-03 16:41:58.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_embeddings\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mEmbedding upload succeeded.\u001b[0m\n",
      "\u001b[32m2023-07-03 16:42:00.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.project\u001b[0m:\u001b[36mcreate_index\u001b[0m:\u001b[36m1081\u001b[0m - \u001b[1mCreated map `oafish-oxford` in project `oafish-oxford`: https://atlas.nomic.ai/map/3d6e6811-f1f1-479c-aae0-8042d9d4542b/8f94a78f-435d-4ffb-bba3-84c2819fd542\u001b[0m\n",
      "\u001b[32m2023-07-03 16:42:00.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_embeddings\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1moafish-oxford: https://atlas.nomic.ai/map/3d6e6811-f1f1-479c-aae0-8042d9d4542b/8f94a78f-435d-4ffb-bba3-84c2819fd542\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "nomic.login(nomic_api_key)\n",
    "id_list = range(len(pdf_embedding['text']))\n",
    "project = atlas.map_embeddings(embeddings= np.squeeze(np.array(pdf_embedding[\"vectors\"]),  axis=1),\n",
    "                               data=[{'id':idx, 'text':text[0], 'category':cat} for idx, text, cat in zip(id_list, pdf_embedding['text'], pdf_embedding['categories'])], \n",
    "                               id_field='id',\n",
    "                               description='pdfs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790a1c28",
   "metadata": {},
   "source": [
    "# Graph Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "726b83d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "neo4j_url = os.getenv('NEO4J_URL')\n",
    "neo4j_user = os.getenv('NEO4J_USER')\n",
    "neo4j_password = os.getenv('NEO4J_PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "732a91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = GraphDatabase.driver(neo4j_url, auth=(neo4j_user, neo4j_password))\n",
    "# # Divide the graph into trunks\n",
    "# def get_pair_nodes (tx):\n",
    "#     pairs_of_nodes = []\n",
    "#     for record in tx.run(\"MATCH (a)-[r]->(b) RETURN labels(a), a.name, type(r), labels(b), b.name\"):\n",
    "#         pair_node = {\n",
    "#             \"start_node_name\": record[\"a.name\"],\n",
    "#             \"start_node_label\":record[\"labels(a)\"][0],\n",
    "#             \"end_node_name\": record[\"b.name\"],\n",
    "#             \"end_node_label\":record[\"labels(b)\"][0],\n",
    "#             \"edge\": record[\"type(r)\"]\n",
    "#         }\n",
    "#         pairs_of_nodes.append(pair_node)\n",
    "#     return pairs_of_nodes\n",
    "\n",
    "# with driver.session() as session:\n",
    "#     pairs_of_nodes = session.execute_read(get_pair_nodes)\n",
    "    \n",
    "# driver.close()\n",
    "\n",
    "# node_names = set()\n",
    "# node_types = set()\n",
    "# edge_types = set()\n",
    "# for p_n in pairs_of_nodes:\n",
    "#     node_names.add(p_n[\"start_node_name\"])\n",
    "#     node_names.add(p_n[\"end_node_name\"])\n",
    "    \n",
    "#     node_types.add(p_n[\"start_node_label\"])\n",
    "#     node_types.add(p_n[\"end_node_label\"])\n",
    "#     edge_types.add(p_n[\"edge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ec6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_dicts = {\n",
    "#     \"text\":[],\n",
    "#     \"vectors\":[],\n",
    "#     \"categories\":[]\n",
    "    \n",
    "# }\n",
    "\n",
    "# for n in node_names:\n",
    "#     node_dicts[\"text\"].append(n)\n",
    "#     node_dicts[\"vectors\"].append(embeddings.embed_documents([n]))\n",
    "#     node_dicts[\"categories\"].append(\"node_name (graphs)\")\n",
    "    \n",
    "# for n in node_types:\n",
    "#     node_dicts[\"text\"].append(n)\n",
    "#     node_dicts[\"vectors\"].append(embeddings.embed_documents([n]))\n",
    "#     node_dicts[\"categories\"].append(\"node_type (graphs)\")\n",
    "    \n",
    "# for e in edge_types:\n",
    "#     node_dicts[\"text\"].append(e)\n",
    "#     node_dicts[\"vectors\"].append(embeddings.embed_documents([e]))\n",
    "#     node_dicts[\"categories\"].append(\"edge_type (graphs)\")\n",
    "    \n",
    "# with open('graph_embedding.json', 'w') as f:\n",
    "#     # Use json.dump to write the data to the file.\n",
    "#     json.dump(node_dicts, f)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cffd938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('graph_embedding.json', 'r') as f:\n",
    "    # Use json.load to load the data from the file.\n",
    "    graph_embedding = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17fa6a1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-03 16:42:03.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.project\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m749\u001b[0m - \u001b[1mCreating project `sad-fairy` in organization `rancheng0918`\u001b[0m\n",
      "\u001b[32m2023-07-03 16:42:05.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUploading embeddings to Atlas.\u001b[0m\n",
      "\u001b[32m2023-07-03 16:42:05.997\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnomic.project\u001b[0m:\u001b[36m_validate_and_correct_arrow_upload\u001b[0m:\u001b[36m254\u001b[0m - \u001b[33m\u001b[1mid_field is not a string. Converting to string from int32\u001b[0m\n",
      "1it [00:02,  2.71s/it]\n",
      "\u001b[32m2023-07-03 16:42:08.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.project\u001b[0m:\u001b[36m_add_data\u001b[0m:\u001b[36m1371\u001b[0m - \u001b[1mUpload succeeded.\u001b[0m\n",
      "\u001b[32m2023-07-03 16:42:08.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_embeddings\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mEmbedding upload succeeded.\u001b[0m\n",
      "\u001b[32m2023-07-03 16:42:10.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.project\u001b[0m:\u001b[36mcreate_index\u001b[0m:\u001b[36m1081\u001b[0m - \u001b[1mCreated map `sad-fairy` in project `sad-fairy`: https://atlas.nomic.ai/map/cb444d6d-c899-4209-ae69-6d18653d4504/1f53bcd8-effa-4820-89c9-7933394b4da9\u001b[0m\n",
      "\u001b[32m2023-07-03 16:42:10.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_embeddings\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1msad-fairy: https://atlas.nomic.ai/map/cb444d6d-c899-4209-ae69-6d18653d4504/1f53bcd8-effa-4820-89c9-7933394b4da9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "nomic.login(nomic_api_key)\n",
    "id_list = range(len(graph_embedding['text']))\n",
    "project = atlas.map_embeddings(embeddings= np.squeeze(np.array(graph_embedding[\"vectors\"]),  axis=1),\n",
    "                               data=[{'id':idx, 'text':text, 'category':cat} for idx, text, cat in zip(id_list, graph_embedding['text'], graph_embedding['categories'])], \n",
    "                               id_field='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d963f00",
   "metadata": {},
   "source": [
    "# View PDF emedding and Graph embedding in the same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1600d65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2024, 1536)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack pdf and graph embeddings\n",
    "pdf_embedding_vectors = np.squeeze(np.array(pdf_embedding[\"vectors\"]),  axis=1)\n",
    "graph_embedding_vectors = np.squeeze(np.array(graph_embedding[\"vectors\"]),  axis=1)\n",
    "\n",
    "all_embeddings_vectors = np.vstack((pdf_embedding_vectors,graph_embedding_vectors))\n",
    "all_embeddings_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ae6ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack data\n",
    "id_list = range(len(pdf_embedding['text']))\n",
    "\n",
    "pdf_data = [{'id':idx, 'text':text[0], 'category':cat} for idx, text, cat in zip(id_list, pdf_embedding['text'], pdf_embedding['categories'])]\n",
    "\n",
    "id_list = range(len(pdf_embedding['text']), len(pdf_embedding['text'])+ len(graph_embedding['text']))\n",
    "graph_data = [{'id':idx, 'text':text, 'category':cat} for idx, text, cat in zip(id_list, graph_embedding['text'], graph_embedding['categories'])]\n",
    "\n",
    "all_data = pdf_data + graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58df8748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-03 16:42:12.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.project\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m749\u001b[0m - \u001b[1mCreating project `delicious-booking` in organization `rancheng0918`\u001b[0m\n",
      "\u001b[32m2023-07-03 16:42:14.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUploading embeddings to Atlas.\u001b[0m\n",
      "\u001b[32m2023-07-03 16:42:14.707\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnomic.project\u001b[0m:\u001b[36m_validate_and_correct_arrow_upload\u001b[0m:\u001b[36m254\u001b[0m - \u001b[33m\u001b[1mid_field is not a string. Converting to string from int32\u001b[0m\n",
      "2it [00:03,  1.94s/it]                                                          \n",
      "\u001b[32m2023-07-03 16:42:18.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.project\u001b[0m:\u001b[36m_add_data\u001b[0m:\u001b[36m1371\u001b[0m - \u001b[1mUpload succeeded.\u001b[0m\n",
      "\u001b[32m2023-07-03 16:42:18.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_embeddings\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mEmbedding upload succeeded.\u001b[0m\n",
      "\u001b[32m2023-07-03 16:42:19.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.project\u001b[0m:\u001b[36mcreate_index\u001b[0m:\u001b[36m1081\u001b[0m - \u001b[1mCreated map `delicious-booking` in project `delicious-booking`: https://atlas.nomic.ai/map/b8455529-dd3b-4075-85fa-b5dc9cac1f42/306c9ecc-e8cd-4591-b7cc-a5d86a60397a\u001b[0m\n",
      "\u001b[32m2023-07-03 16:42:19.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_embeddings\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mdelicious-booking: https://atlas.nomic.ai/map/b8455529-dd3b-4075-85fa-b5dc9cac1f42/306c9ecc-e8cd-4591-b7cc-a5d86a60397a\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "project = atlas.map_embeddings(embeddings= all_embeddings_vectors,\n",
    "                               data=all_data, \n",
    "                               id_field='id',\n",
    "                               colorable_fields=['category']\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e16860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b436a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f4c61f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat",
   "language": "python",
   "name": "chat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
